\chapter{Einführung}
Das Hochhalten von Softwarequalität ist eine sehr anspruchsvolle Aufgabe, welche eine gewisse Planung vorraussetzt. Gerade bei Projekten mit hohen Budgets und materiellen Einsätzen werden hohe Anforderungen an das Qualitätsmanagement gesetzt.

Einige bekannte Fehlschläge in der Softwareentwicklung hätten wahrscheinlich mit besseren Qualitätssicherungsmaßnahmen verhindert werden können:

\begin{itemize}
    \item Pioneer 4 verfehlte den Mond
    \item unnötige Mahnungen durch die französische Finanzverwaltung
    \item das Herausgeben von faulen Krediten, was schlussendlich zum Bankencrash geführt hat
    \item Verlust einer Segelyacht im Pazifik
\end{itemize}

\section{Verifikation und Validierung}
Die Begriffe sollten klar getrennt werden, da sie nicht synonym verwendet werden können, und bei Softwareprozessen und Softwarequalität eine gewichtige Rolle spielen.

Die Verifikation stellt fest ob die Software mit der vorhandenen Spezifikation übereinstimmt, wohingegen die Validierung bestimmt ob die Software für den Kunden auch wirklich nützlich ist.

\section{Technical Debt}
Technical Debts sind ein wichtiges Thema in der Qualitätssicherung. Der Begriff wurde aus dem Finanzwesen übernommen (Debt = Schulden). In der Softwareentwicklungen ist damit gemeint, dass ungeschickte Lösungen irgendwann gefixt werden müssen.

Diese technische Schulden kann man bewusst eingehen, um Termine zu halten. Allerdings muss man immer im Hinterkopf behalten, dass man diese Schulden zu einem späteren Zeitpunkt auch wieder bezahlen muss.

Einer der größten Unterschiede zwischen klassischen und agilen Projektmanagementmethoden ist der Umgang mit diesen technischen Schulden. Bei agilen Methoden werden diese Schulden bewusst eingegangen, um ein schnelleres iteratives Vorgehen zu gewährleisten. Bei diesen Methodiken ist allerdings auch die Gefahr einer Überschuldung ungleich höher als bei den klassichen.

Allerdings werden in der Regel auch bei klassischen Methoden technische Schulden verursacht, nämlich in Form von Änderungen in den Anforderungen, auf welche in agilen Methoden besser reagiert werden kann.

\chapter{Hausaufgabe Besprechnung}
Die Aufgabe war ein Programm zu schreiben, welches in der Lage ist nach Eingabe der Koeffezienten eine quadratische Gleichung zu lösen.

Bei der Besprechung der Hausaufgabe wurde auf folgende Punkte aufmerksam gemacht:

\begin{itemize}
    \item Klare Definition für Verhalten in Sonderfällen (z.B. komplexe Zahlen da in Wurzel negative Zahl)
    \item Gleitkommazahlen sollten auf Grund von Rundungsfehlern vermieden werden
    \item Statt der Standardformel ein eigenes Näherungsverfahren implementieren, um den Rundungsfehler zu minimieren
\end{itemize}

\chapter{Wichtige Begriffe}

\begin{itemize}
    \item Softwareprozesse (Abfolge von Tätigkeiten, durch die ein Software-Produkt entsteht)
    \item Vorgehensmodell (Vereinfachte Beschreibung eines Softwareprozesses)
    \item Methode (Strukturierter Ansatz für die Software-Entwicklung)
\end{itemize}

\section{Software-Engineering}
Software-Engineering ist eine technische Disziplin  welche eine Lösung für den Anwender bieten will unter Einsatz von Theorien, Methoden und Werkzeugen und Berücksichtigung von Organisation, Management und Entwicklung. 

\section{Informatik}
Grundlage der Wissenschaft für Software-Ingeneure (Theorie, Konzepte, ...).

\section{ESSENCE Kernel Overview}
\img{0.9}{document/graphics/essence_kernel_overview.png}{ESSENCE Kernel Overview}{EKO}
In diesem Model gibt es verschiedene Zustände für die Anforderungen und jeder dieser Zustände hat selbst wieder Kriterien welche einem dabei helfen in welchem Zustein ein Projekt ist.
\paragraph{Zustände:}
\begin{itemize}
    \item Conceived
    \item Bounded
    \item Coherent
    \item Accepted
    \item Adressed
    \item Fulfilled
\end{itemize}

\section{Qualität}
Grad in dem die inhärenten Eigenschaften des Produkts Anforderungen erfüllen.

\begin{itemize}
	\item \textbf{Explizite Anforderungen}
	\item \textbf{Implizite Anforderungen} - Anforderungen welche existieren aber den Stakeholdern nicht bewusst sind.
	\item \textbf{Nicht explizite Anforderungen} - Stakeholer wissen, dass sie diese Anforderungen gibt aber sie teilen diese nicht mit (sind quasis eh klar).
	\item \textbf{Objektiv} - Vollkommen klar, dass man etwas braucht.
	\item \textbf{Subjektiv} - Vermeintliche Anforderungen, welche nicht wirklich wichtig sind.
	\item alle betroffenen / interessierten Personen
\end{itemize}

\subsection{Begriffsabgrenzung}
\paragraph{Technisches computer-basiertes System} System welches ausschließlich  aus Soft- und Hardware-Komponenten besteht.
\paragraph{Soziotechnisches System} System bestehend aus einem oder mehreren technischen Systemen, den Menschen die es bedienen, den notwendingen Arbeitsprozessen, organisatorischen Richtlinien, usw.

\emph{Systeme:}
\begin{itemize}
	\item haben systemspezifische Eigenschaften die nur dem System als Ganzem zugeordnet werden können
	\item sind häufig nicht deterministisch
	\item hängen von organisatorischen Zielen ab
\end{itemize}

\section{Kritische Systeme}
Relevante Systemeigenschaften für kritische Systeme sind:
\begin{itemize}
	\item Reparierfähigkeit
	\item Wartbarkeit
	\item Überlebensfähigkeit
	\item Fehlertoleranz
\end{itemize}

\paragraph{Kritisches System}
Systeme, bei dessen Ausfall oder Fehlfunktion großen Schaden anrichten kann (wirtschaftliche Verluste, physische Schäden, Gefahr für Gesundheit und Leben von Menschen).

\paragraph{Sicherheitskritisches System}
Schäden an der Umwelt und/oder Gefahr für Gesundheit und Leben von Menschen (Bohrinsel im Golf von Mexiko).

\paragraph{Aufgabenkritisches System}
Aufgaben die ein System erledigen solle werden nicht durchgeführt (z.B. Bank).

\paragraph{Geschäftskritisches System}
Extrem hohe Kosten bzw. signifikante Gewinnausfälle können die Folge eines Systemausfalls sein.

\chapter{Anforderungen}

\section{Sammlung von Anforderungen}

\subsection{Interviews}
\paragraph{Technik}
\begin{itemize}
\item Interviews mit Fragebogen
\item Geschlossene Interviews vorgegebener Fragebogen abarbeiten
\item Offene Interviews mit einer Diskussion zwischen Analyseteam und Beteiligten
\end{itemize}

\paragraph{Durchführungsempfehlung}
\begin{itemize}
\item Mischung aller Methoden 
\item Vorbereitung aller Diskussionen als geschlossenes Interview 
\item gut und interessiert zuhören
\item gezielt Fragen
\end{itemize}

\paragraph{Probleme}
\begin{itemize}
\item Jargon des Anwendungsgebiets 
\item Implizites Wissen
\end{itemize}

\paragraph{Eignung}
\begin{itemize}
\item Verständnis der Benutzeranforderungen 
\item Ergänzung zu anderen Informationsquellen mit zum Beispiel Dokumentationen oder Beobachtungen
\end{itemize}

\paragraph{Szenarien}
\begin{itemize}
\item {
Grundbestandteile
\begin{itemize}
\item Ausgangssituation
\item Ereignisablauf
\item Ausnahmen und ihre Behandlung
\end{itemize}
}
\item {
Varianten
\begin{itemize}
\item Ad-hoc
\item Formell
\end{itemize}
}
\end{itemize}

\subsection{Ethnografische Methode (Völkerkunde)}
Grundidee: Beobachten ohne einzugreifen

\begin{itemize}
\item Beobachten der alltäglichen Arbeit im normalen Umfeld
\item Notieren von Auffälligen
\item Diskussion mit Experten
\item Ableitung der Anforderungen
\end{itemize}

\paragraph{Stärken}
\begin{itemize}
\item Erkennen von impliziten Anforderungen 
\item Erkennen von nicht explizierten Anforderungen
\item Erkennen von Abweichungen
\end{itemize}

\img{0.9}{document/graphics/ethnogfrafisch.png}{Verknüpfung von Ethografie und Prototypen nach Sommerville (Copyright Pearson Studium 2007)}{ethnogfrafisch}

\newpage
\section{Klassifizierung von Anforderungen}

\img{0.8}{document/graphics/metamodel.png}{Metamodell}{metamodel}

\paragraph{Aufgaben}

\begin{itemize}
\item Erkennen von Duplikaten / Synonymen 
\item Beziehungen zwischen Anforderungen 
\item Gruppierung der Anforderungen 
\end{itemize}

\section{Validierung von Anforderungen}
Wichtige Prüfungen sind:

\begin{itemize}
\item Gültigkeitsprüfung
\item Konsistenzprüfung
\item Vollständigkeitsprüfung (schwierig, aber mit etwas Bauchgefühl machbar)
\item Realisierbarkeitsprüfung
\item Verifizierbarkeitsprüfung
\end{itemize}

\subsection{Techniken}
Prototypen erstellen und Testfälle entwickeln. Falls das nicht möglich sind die Anforderugnen schlecht definiert.

\subsection{Review}
\paragraph{Teamzusammensetzung}
Es sollten Vertreter aller am Projekt beteiligten bzw. vom Projekt betroffenen Gruppen auf Anwenderseite, ausserdem Systemarchitekten und Vertreter der Softwareentwickler.

\paragraph{Durchführung}
Die Führung der Analyse liegt bei den jeweiligen Anwendervertretern. Diskutiert werden sollten alle Anforderungen. Dadurch können Fehler, Konflikte und Wiedersprüche aufgedekt werden. Das Ergebnis ist ein Review Bericht.

\paragraph{Prüfungen}
Die Konsistenz der Anforderungen sollten am Ende geprüft werden. Ausserdem sollte eine Vollständigkeitsprüfung durchgeführt werden.

\subsection{Priorisierung von Anforderungen}

\paragraph{Grundgedanke}
Phasenweise Implementierung der Software. 

\subsubsection{Prioritätsfestlegung}
Teams festlegen, die nicht miteinander kommunizieren sollten. Ausserdem wird eine Bewertungsformel festgelegt.

\paragraph{Nutzwertanalyseteam}
Bewertet den Nutzen für die Anwender.

\paragraph{Kostenanalyseteam}
Schätzt die Kosten jeder Anforderung


\subsubsection{Auswertung}

\paragraph{Einflussgrößen}
\begin{itemize}
\item Nutzwert jeder Anforderung
\item Kosten jeder Anforderung
\item Obergrenze des Aufwands für Stufe 1
\item Abhängigkeiten
\end{itemize}

\paragraph{Ergebnis}
Liste der Anforderungen für nächste (bzw. erste) Ausbaustufe

\newpage
\section{Systemmodelle}

\paragraph{Kontextmodelle}
Definiert die Systemgrenzen des Gesamtsystems und des technischen Systems. Das Gesamtsystem umfasst das Technische System und die Menschliche Komponente und definiert den Kontext. Das Technische System definiert den Scope.

\img{1}{document/graphics/kontextmodelle.png}{Kontextmodelle}{kontextmodelle}

\newpage
\paragraph{Verhaltensmodelle}
Definiert die Abläufe in einem System. Sie können Datenfluss (Datenfocus) - oder Ereignis (Ereignisfocus) - Orientiert geschehen. Aussderm gibt es Mischformen davon. Dafür können Datenflussdiagramme (Abbildung \imgref{verhaltensmodelle}), Zustandstabelld (Abbildung \imgref{zustandstabelle}) und ähnliches verwendet werden.
 
\img{1}{document/graphics/verhaltensmodelle.png}{Datenflussdiagramm}{verhaltensmodelle}

\img{1}{document/graphics/zustandstabelle.png}{Zustandtabelle}{zustandstabelle}

\paragraph{Datenmodelle}
Definiert die logische und persistente (lokal, übergreifend mttels Datenbank und Datenaustausch) Datenstruktur. Dazu kann ER-, UML-Diagramme, OWL oder andere Ontologie-Darstellungen und andere.
 
\newpage
\paragraph{Objektorientierte Modellierung}
Vereinigt die Funktionalität von Daten- und Verhaltensmodelle und können Daten, Datenflüsse, Datenstrukturen und Erreignise erfassen. Als Notation wird meist UML verwendet.

\img{1}{document/graphics/objektorientiert.png}{Objektorientierte Modellierung}{objektorientiert}

Sind die Klassen in dem Diagramm Abbildung \imgref{objektorientiert} wirklich \textbf{Klassen oder Rollen}? Nein das sind eindeutig Rollen.

\newpage
\paragraph{Strukturierte Methoden}
Detailliert definierte Vorgehensweise bei der SW-Entwicklung. Normalerweise basierend auf einem Satz von Diagrammtypen. Definiert zusätzliche Regeln und Richtlinien. Beispiele dafür sind JSP, V-Modell oder RUP. Nachteile davon sind Mangelnde Unterstützung nicht-funktionaler Anforderungen und Anwendbarkeit für konkretes Problem oft schwer zu entscheiden.

\img{1}{document/graphics/strukturiert.png}{Strukturierte Methoden}{strukturiert}

\section{Anforderungsmanagementsystem}
Die Anforderungen an ein System ändern sich mit der Zeit, diese können ursprünglich unvollständig sein. Oder es verbessert sich das Verständnis des Problems / es ensteht eine bessere Sicht der Dinge. Aber auch das Umfeld kann sich verändern, z.B. wirtschaftlich, technisch, juristisch ...

Der Prozess umfasst:

\begin{itemize}
\item {
das
\begin{itemize}
\item Sammeln 
\item Verstehens 
\item Klassifizierens 
\item Validierens 
\item Priorisierens
\end{itemize}
}
\item {
von
\begin{itemize}
\item Anforderungen 
\item Änderungen der Anforderungen 
\end{itemize}
}
\item {
und ihren Auswirkungen auf 
\begin{itemize}
\item andere Anforderungen 
\item Entwurfsentscheidungen
\item das System
\end{itemize}
}
\end{itemize}

\paragraph{Dauerhafte Anforderungen}
Sie sind relativ stabil und sind mit dem Kern der Anwendung verwoben. Oft aus Standardisierten Modellen entnohmen.

\paragraph{Veränderliche Anforderungen}
Anforderungen mit hoher Änderungswahrscheinlichkeit. Können wirtschaftliche Randbedingungen, technische Randbedingungen und gesetzliche Randbedingungen.

\section{Pflichtenheft}
Zusammenstellung der vollständigen und detailierten Benutzeranforderungen und Systemanforderungen (großes Problem ist die Vollständigkeit). Darf nach Fertigstellung nicht mehr geändert werder und muss so implementiert werden wie es festgehalten wurde (auch wenn sich die darin enthaltenen Entscheidungen als falsch herrausstellen). Dies muss aus juristischen Gründen so sein, da eine nachträgliche Änderung als eine Benachteiligung der Mitbewerber interpretiert werden kann.

\paragraph{Synonyme} sind die Begriffe Produktdefinition, Produktspezifikiation, Systemdefinition und Systemspezifikation.

\paragraph{Adressaten des Pflichtenhefts} sind unter anderem Systemkunde, Manager, Systementwickler, Systemtester, Systemwarter und Juristen. 

\paragraph{Informationen im Pflichtenheft} sind qualitative und quantitative Anforderungen (mandatory requirement) sowie zusätzliche Wünsche (optional requirements) dessen Erfüllung als sehr positiv betrachtet werden und informative Bestandteile. Diese Bestandteile dienen dem Verständniss und sind streng genommen unverbindliche Informationen.

In vielen Ländern gelten Abbildungen, Tabelle und Anhänge als informative Bestandteile, wenn sie nicht anderst gekennzeichnet sind (engl. "normativ").

\paragraph{Aufbau des Pflichtenhefts}
\begin{itemize}

\item { Einleitung
\begin{itemize}
\item Ziele des Pflichtenhefts
\item Anwendungsbereich des Produkts
\item Definitionen, Akronyme und Abkürzungen
\item Referenzen
\item Überlick über das Pflichtenheft
\end{itemize}
}

\item { Allgemeine Beschreibung
\begin{itemize}
\item Produktperspektive
\item Produktfunktion
\item Produktcharakteristika aus Benutzersicht
\item Beschränkungen
\item Voraussetzungen und Abhängigkeiten
\end{itemize}
}

\item Spezifische Anforderungen (funktionale u. nicht funktionale Anforderungen)

\item Anhänge
\item Index

\end{itemize}

\section{Anforderungensarten}

\paragraph{Funktionale Anforderungen} unterstützen Definition von Funktionen zur Fehlerprüfung, zur Wiederherstellung im Fehlerfall und Aspekte zum Schutz gegen Systemausfälle.

\paragraph{Als nichtfunktionale Anforderungen} werden u.a. die Systemzuverlässigkeit und Systemverfügbarkeit festgelegt. 

\paragraph{Negativanforderungen} Beschreibung von Verhalten oder Eigenschaften, die das System auf keinen Fall zeigen darf.

\section{Risikomanagement}
Risikomanagement besteht aus Gefahrenbestimmung, Risikoanalyse und Gefahrenklassifizierung, Gefahrenvereinzelung und Festlegung zur Risikominimierung.

\paragraph{Murphys Law} Alles was schief gehen kann, wird irgendwann einmal schief gehen.

\paragraph{Risikoerkennung} Ziel ist es zu Erkennen von Rsikiken und Gefahren. Probleme die dabei entstehenkönnen sind die Wechselwirkung zwischen Systemkomponenten bzw. die Wechselwirkungen mit der Umwelt. 

\paragraph{Risikoanalyse und Risikoklassifizierung} Analyse von  Unfallwahrscheinlichkeit, Schadenswahrscheinlichkeit und Schadeshöhe. Risiken sind klassifizierbar in:

\begin{itemize}
\item { nicht tolerierbar
\begin{itemize}
\item großer Schaden und / oder hohe Schadenswahrscheinlichkeit
\item Maßnahmen: unter allen Umständen Risiko ausschließen
\end{itemize}
 }
\item {as low as reasonably possible (ALARP)
\begin{itemize}
\item höchstens mittleres Schadenspotential und mittlere Schadenswahrscheinlichkeit
\item Maßnahmen: zumindestens Auschluss des Schadens unter Beachtung von wirtschaftlichen, vertraglichen oder technischen Randbedingungen
\end{itemize}
 }

\item { vernachlässigbar
\begin{itemize}
\item geringes Schadenspotential und / oder geringe Schadenswahrscheinlichkeit
\item Maßnahmen: Reduzierung der Schadenswahrscheinlichkeit ohne negativen Einfluss auf wirtschaftliche, technisches, oder vertragliche Randbedingungen oder andere Systemanforderungen
\end{itemize}
}

\end{itemize}


\paragraph{Risikozerlegung} Ziel es die Ursachen aufzudecken. Dazu können Reviews, Checklisten, Petri-Netze, formale Login und Fehlerbäume verwendet werden.

\img{0.9}{document/graphics/fehlerbaum.png}{Fehlerbaum}{FB}

\paragraph{Risiko-Minimierung} Ziel ist das Vermeiden des Auftretens von Gefahren. In der Praxis bedeutet dies eine Kombination aller Strategien.

\section{Betriebssicherheit}

\img{0.9}{document/graphics/betriebssicherheit.png}{Betriebssicherheit nach IEC 61508}{BS}

\paragraph{Klassifizierung}

\begin{itemize}
\item Klasse 1 - Fehler die andere Anwedungen betreffen können
\item Klasse 2 - Fehler die andere Benutzer der selben Anwedung betreffen können
\item Klasse 3 - Wesentliche Funktion steht ohne Work-Around nicht zur Verfügung
\item Klasse 4 - Wesentliche Funktion steht nur über Work-Around zur Verfügung bzw. Sekundärfunktion steht nicht zur Verfügung
\item Klasse 5 - Verbesserungswunsch
\end{itemize}

\section{Systemsicherheit} Hierbei geht es um direkte und indirekte Berodhungen.

\paragraph{Direkte Bedrohung} wie z.B. unbefugtes Eindringen und DOS.

\paragraph{Indirekte Bedrohung} wie Aufwand um Sicherheitsmaßnahmen zu installieren, konfigurieren und aktuell zu halten. Auch inkludiert sind Fehler und Nachlässigkeiten der Systemverwalter und monopolartige Stellungen einiger Hard- und Softwareanbieter da eine weite Verbreitung von Sicherheitslücken sehr wahrscheinlich ist.

\img{0.9}{document/graphics/sicherheit.png}{Sicherheit}{Sec}

\section{Zuverlässigkeit} besteht aus Hardware-, Software- und Bedienerzuverlässigkeit. 

\img{0.9}{document/graphics/zuverlaessigkeit.png}{Zuverlässigkeit}{Zuv}

\img{0.9}{document/graphics/zuverlaessigkeit2.png}{Zuverlässigkeit nach Sommervill}{Zuv}

\paragraph{Extreme Zuverlässigkeitsanforderungen} lassen sich nicht testen!

\section{Formale Spezifikationsmethoden}
An dieses Thema sind seit 1970 sehr hohe Erwarungen gerichtet aber der große Durchbruch blieb bisher aus. Gründe dafür sind die Entwicklung anderer Software-Engineering-Methoden, Marktveränderungen, beschränkte Einsetzbarkeit und mangelhafte Skalierbarkeit. 

Erfolgreich verwendet wirds bei Raumfahrt-, und medizinischen Systemen sowie bei Überwachung des Luftverkehrs. 

\img{0.9}{document/graphics/formale-spezifikationsmethoden.png}{Formale Spezifikationsmethoden im Softwareprozess}{FSIS}

\paragraph{Fazit}
Formale Spezifikationstechniken sind gute Ergänzungen, eindeutig und präzise aber schwer verständlich für den Laien. Erzwingen die frühzeitige Analyse der Systemanforderungen wenn die Fehlerbehebung noch billig ist.

\section{Beispiel: Anforderungen an Quadratische Gleichungen lösen}

\begin{itemize}
\item Ergebnis x element aus Reelen Zahlen : $ax^2+bx+c=0$
\item Kein Absturz bei komplexer Lösung
\item {
Vernünftige Reaktion auf Eingabefehler
\begin{itemize}
\item unvollständig
\item $4ac > b^2$
\end{itemize}
}
\item Maximaler Rundungsfehler: Relativ 0,1\% + Beweis
\item Immer Definiertes Ergebnis (Ausnahmebehandlung)
\item Keine Endlosschleife
\item {
Zeitbedarf max 1mSec
\begin{itemize}
\item Verwendeter CPU / Prozessor / Rechner
\item Maximal 2xSQRT einer bestimmten implmentierung
\end{itemize}
}
\item {
Signatur
\begin{itemize}
\item Nmae
\item parameter
\item Ergebnis (Return)
\end{itemize}
}
\end{itemize}

\chapter{Entwicklung}

\paragraph{Strategien}
\begin{itemize}
\item Fehlervermeidung
\item Fehlerentdeckung
\item Fehlertoleranz
\end{itemize}

Laut der Kostenentwicklung nach Sommerville ist eine Software mit vielen Fehlern günstiger als eine Software mit weniger Fehlern. Jedoch steigen die Kosten nicht linear sondern exponentiell.

\paragraph{Techniken}
\begin{itemize}
\item Verlässliche Softwareprozesse
\item Qualitätsmanagement
\item Formale Spezifikation
\item Statische Verifikation (Probleme durch Reviews beheben)
\item Starke Typisierung
\item Sichere Programmierung
\item Ausnahmebehandlung
\item Geschützte Information
\end{itemize}

\section{Fehlervermeidung}
\paragraph{Verläsliche Softwareprozesse}

\begin{itemize}
\item Inspektion der Anforderungen
\item Anforderungsmanagement
\item Überprüfung der Modelle: statisch / dynamisch
\item Inspektion des Entwurfs / Codes
\item Statische Analyse des Codes (Review)
\item Planung und Management von Tests
\item Konfigurationsmanagement
\end{itemize}

\section{Sichere Programmierung}
\begin{itemize}
\item sichere verwendung von GOTO (mach da weiter ohne überprüfung)
\item sichere verwendung von POINTER (such da mal nach deinen daten => goto in der Datenwelt)
\item Rundungsfehler von Gleitkommazahlen
\item Dynamische Speicherallokierung
\item Parallelität
\item Rekursion
\item Interrupts
\item Vererbung
\item Aliasing
\item Fehlende Überprüfung von Arraygrenzen
\item Konfiguationsdateien
\end{itemize}

\paragraph{Ausnahmebehandlung}
Wird in manchen Sprachen mangelhaft Unterstützt (Beispiel: C). Kann auch dazu verwendet werden um die Lesbarkeit der Anwendung zu erhöhen und damit können Fehler vermieden werden.

\section{Fehlertoleranz}

\paragraph{Fehlererkennung}
Typen sind Vorbeugend (ich versuche vorher Fehler zu erkennen) und Rückblickend (ich behebe den Fehler wen einer auftritt => z.B. die Transaktion zurücksetzen).

\paragraph{Wichtige Hilfsmittel}
Validierung: Invarianten, Vorbedinungen, Nachbedinungen => dürfen nicht abschaltbar sein.

\paragraph{Wiederherstellung nach Fehlern}
Pesimistisch (nur zurücksetzen geht nicht ...) oder Optimistisch (erneut versuchen den gewünschten zustan zu erreichen).

Vorbeugende Fehlererkennung hilft diesen Aufwand zu vermeiden.

\section{Fehlertolerante Architekturen}
\paragraph{Widerherstellungsblöcke}
Verschiedene Algorithmen implementieren. Im Betrieb den ersten ausführen und testen, bei Fehler nimm nächsten Algorithmen. Probleme: Rundungsfehler

\section{Wartungsaufwand}
Gründe für hohen Wartungsaufwand sind Informatinosmanagement (Verlust des Entwicklungsteam und seiner Erfahrung), Vertragliche Zuständigkeit (Entwicklung von einer Firma, wartung von einer anderen), Fähigkeiten der Metarbeiter (Mangelnde Erfahrung mit dem Anwendungsgebiet und Technologien) und Alter bzw. Struktur des Programs (Dokumentation nicht mehr aktuell oder nicht verhanden, fehlendesKonfigurationsmanagement).

Zusätzlichen Entwicklungsaufwand um Software besser wartbar zu machen zahlt sich im allgemeinen nicht aus. 

\section{Weiterentwicklungsprozesse}
Es gibt für jede Anforderung einen passenden Prozess (laufende weiterentwicklung, änderungungen, Bug-Behebungen, ...)

\subsubsection{Software-Reengineering}
Dabei handelt es sich um eine Neuentwicklung von Software, meistens eine Umstellung auf neuere Technologien (z.B. von COBOL auf Java).

Dafür ist auch das Beherrschen der alten Technologien notwendig, da man andernfalls das alte System nicht analysieren kann. Die Beweggründe hinter der Umstellung ist ein verringertes Risiko und geringere Kosten.

Normalerweiße teilt sich das Reengineering in Reverse Engineering und in eine Verbesserung der Programmstruktur. Im Anschluss daran müssen natürlich auch die Daten auf eventuell neue Formate transformiert werden.

\subsubsection{Legacy Systeme}
Legacy Systeme werden nach zwei Kriterien beurteilt: Qualität und Geschäftswert.

Wenn beide Kriterien schlecht sind wird die Software nicht mehr weiterentwickelt. Bei hoher Qualität kann man das einfach weiter laufen lassen, bei hohem Geschäftswert aber niedriger Qualität wird das komplett neu geschrieben, und wenn beide Kriterien hoch einzustufen sind rentiert sich ein Software Reengineering Ansatz.

\chapter{Testing}
Betrifft die Kernel Alphas Softwaresystem, Requirements und Work. Tests sollen uns helfen Probleme zu entdecken und beheben, die Kunden überzeugen und die Softwarequalität demonstrieren. Dabei ist allerdings zu beachten, dass nur die Anwesenheit von Fehlern getestet werden kann, allerdings nicht ihre Abwesenheit.

\begin{itemize}
    \item Fehlverhalten (Failures) beschreiben ein inkorrektes Verhalten eines Systems zur Laufzeit
    \item Fehler kommen wirklich im Quellcode vor
    \item Irrtürmer (Errors) sind inkorrekte Wahrnehmungen von Menschen
\end{itemize}

Dabei muss es nicht zwingendermaßen sein dass nicht jeder Irrtum zu einem Fehler, und nicht jeder Fehler zu einem Fehlverhalten führt.

Für die Reduzierung von Fehlern gibt es verschiedene Maßnahmen, z.B. das 4-Augen-Prinzip zur Vermeidung, Tests zum Entdecken, und standardisierte Prozesse zum Beseitigung von Fehlern.

Weiters wird zwischen Blackbox- und Whitebox-Tests unterschieden, bei Blackbox Tests wird rein gegen die Spezifikation getestet, ohne den Code zu testen, wohingegen Whitebox-Tests den Code berücksichtigen.

Ein weiterer Typ ist ein Regressionstest, der neben der erwarteten Funktionalität sicherstellen soll, dass das System frei von alten Fehlern ist. Das Einführen alter Fehler kann sehr schnell passieren, wenn Code mit anderen Absichten refactored wird.

Ein Testfall wird in einen abstrakten und konkreten Teil eingeteilt. Der abstrakte Teil beschreibt den Test, der konkrete ist eine Ausführung des Tests. Eine Testsuite vereint mehrere Tests zu einer Ausführungseinheit.

\section{Testprozesse}
Ein Testprozess muss geplant und vorbereitet werden. Dazu gehören die Definitionen der Testziele und verwendeten Messungen, sowie die Eingabewerte und Testsuites.

Die Messungen müssen dann auch noch analysiert werden, vor allem geht es da um das Auffinden von Fehlern. Diese Fehler müssen von Softwareentwicklern behoben werden, insofern bei der Planung der Messungen keine Fehler gemacht werden. Bei TDD testen sich die Software und Tests gegenseitig, da beim Auftreten eines Fehlers sowohl das System under Test als auch der Test selbst fehlerhaft sein kann.

\subsection{Teststrategien}
\subsubsection{Ausprobieren}
Planloses Ausprobieren ist die häufigste Form des Testens, allerdings ist diese Form des Testens in vielen Fällen unzureichen. Es liefert keine reproduzierbare Ergebnisse, und erlaubt auch keine Aussage über die Qualität.

Das ist vor allem unzureichend wenn man eine Gewährleistung auf die Software geben will. Die rechtlichen Rahmenbedingungen sind momentan noch im Sinne der Softwareanbieter, allerdings könnte sich das in Zukunft ändern, gerade selbstfahrende Autos könnten da Ausschläge in diese Richtung geben.

\subsubsection{Vollständiges Testen}
Das vollständige Testen ist meist theorethisch möglich, aber nur in den seltensten Fällen wirtschaftlich. Unser Ziel muss es deshalb sein eine möglichst hohe Testabdeckung zu erreichen, und dabei auch noch wirtschaftlich zu bleiben.

\subsubsection{Checklisten}
Ein mögliches Vorgehen sind Checklisten, die die wesentlichsten Funktionen des Systems definieren, und nur diese getestet werden. Natürlich kann man Checklisten auch für andere Kritieren definieren.

Wenn man sichere Aussagen über die Qualität machen will, wird man sehr umfangreiche Checklisten bekommen. Andererseits ist der Vorteil das man eine verbesserte Reproduzierbarkeit erhält, allerdings wird sich niemand die Zeit nehmen vollständige Checklisten zu erstellen.

\subsubsection{Partitionen}
Eine Partition ist eine nicht überlappende Menge von Untermengen einer Menge, die bei der Beseitigung der Nachteile von Checklisten behilflich sein können. Diese Untermengen werden als Äquivalenzklasse bezeichnet, und es reicht wenn nur ein Element einer Äquivalenzklasse getestet wird. Bei sinnvoller Partitionierung kann der Testaufwand bei gleichzeitig erhöhter Qualität verringert werden.

Durch die gleiche Gewichtung der Äquivalenzklassen führt allerdings zu unwirtschaftlicher Verteilung der Testaufwände. Administrationwerkzeuge werden z.B. weit weniger aufgeruft, und haben dadurch schon eine niedriger Fehlereintrittwahrscheinlichkeit. 

\subsubsection{Benutzungsprofile}
Da das Testen mit Partitionen immer noch sehr aufwändig sein kann, ist die Verwendung von Benutzungsprofilen möglich. Dabei wird die Benutzung der Partitionen mit einberechnet, und man kann damit mehr Testaufwand für mehr benutzte Partitionen aufwenden.

Bei existierenden Produkten kann für die Erstellung der Benutzungsprofile anhand des aktuellen Produkts bzw. von Vorgängerversionen gemacht werden. Bei neuen Produkten muss man hier wohl auf ein Konkurrenzprodukt zurück greifen. Bei einem komplett neuartigen Produkt bleibt einem nur noch das Schätzen übrig, wobei man hier auf Fachleute der jeweiligen Domäne heranziehen sollte.

Hilfreich ist hier die Definition von Kundenprofilen, die danach anhand der Benutzung gewichtet werden.

\subsubsection{Überdeckung}
Die Partitionen werden auf Basis der Eingabedaten gemacht. Die Eingaben in einer Partitionen müssen gleich behandelt werden. Z.B. realle/imaginäre Lösung der Eingabe für unser Lösungsprogram.

Die größte Fehlerwahrscheinlichkeit besteht an der Partitionsgrenzen. Wenn ein Array z.B. 100 Elemente umfasst, so sollte auch das Einfügen am Index 100 getestet werden, da hier bereits kein Fehler auftreten sollte.

Partitionen sollten Überlappungsfrei und vollständig sein, um eine möglichst hohe Testqualität zu gewährleisten. Für jede Unterdomäne müssen Eingaben ausgewählt werden, für die dann Tests durchgeführt werden. Im Idealfall werden so alle Möglichkeiten im Code abgearbeitet.

Probleme die auftreten können sind unter anderem widersprüchliche Verarbeitungsregeln (überlappende Unterdomänen) oder Probleme mit Rundungsfehlerdurch Grenzdefinitionen. Auch überflüssige Grenzen werden in einen unnötig hohen Testaufwand resultieren.

\paragraph{Schwache Nx1-Strategie}
Es werden N unabhängige Testpunkte auf den Granzen ausgewählt + einen zusäzlichen Testpunkt der nicht auf der Grenze liegt (in minimalem abstand von der Grenze). Dadurch können Abschlussprobleme, Grenzverschiebungen und fehlende Grenzen erkannt werden. Zsätzlich können überflüssige Grenzen erkannt, aber nicht notwendigerweise alle.

\subsubsection{Endliche Automaten und Markov-Modelle}
Die meisten Anwendungsprogramme lassen sich als endliche Automaten mit Ausgabe darstellen. Allerdings ist die Anzahl meist zu hoch zum testen. Es sind vereinfachungen notwendig.

Diese Teststrategie eignet sich für Web-Applikationen. Man beschränkt sich auf relevante Seiten und lösst dadurch Eintritts und Austrittsprobleme.

Für die Konstruktion werden die Zustände, Übergänge definiert, dadurch können die IO-Beziehungen abgeleitet werden und das Modell validiert werden. Ziele für die Zutände sind z.b. die Erreichbarkeit, Vollständigkeit und die Notwendigkeit zu testen. Ziele für die Übergänge sind z.b. die Durchführbarkeit, Vollständigkeit und die Notwendigkeit zu testen.

\paragraph{Markov-Modelle / -Ketten} sind endliche Automaten mit Wahrscheinlichkeiten an jedem Zustandsübergang. Die Addition der Wahrscheinlichkeiten kann unter 100\% fallen wenn nicht alle Möglichkeiten bekannt sind.

Die Wahrscheinlichkeit eines konkreten Übergangs ist das Produkt aller Wahrscheinlichkeiten auf dem Pfad vom Start bis zum Ausgangszustand, multipliziert mit der Wahrscheinlichkeit dieses konkreten Übergangs => diese Tatsache knn bei Schleifen Probleme machen.

\paragraph{UMM - Unified Markov Model} ist ein kohärenter Satz von hierarchisch geschachtelte Markov-Modellen. Kann in der Praxis sehr gut angewendet werden. Es können alle Arten von statistischen Aussagen getätigt werden.

\subsubsection{Kontrollfluss}
Das Testziel ist die ausführung aller Pfade im Programm zu testen. Dazu wird ein CFG (Control Flow Graph) erzeugt. Die Knoten sind ausführbare Anweisungen, Startknoten sind erste, Endknoten sind die letzten Anweisungen und die Kanten sind mögliche Verarbeitungssequenzen.

Bei Schleifen können die Anzahl der Ausführung getestet werden (0, 1, 2 Durchläufe und evtl. die Grenzfälle - bei einer Vorhersehbare durchläufe). Es wird empfohlen die Pfade von hinten her aufzubauen. Dies unterstützt die Identifikation von unbenötigtem Code.

\subsubsection{Datenfluss}
Bei einem \textbf{DDG - Data Dependency Graph} sind die Knoten die Zustände derVariblen und die Kanten sind Operationen des Programmes. Er beschreibt den Zustand von der Variable X in jedem Zeitpunkt.

Die Richtung der Pfeile bestimmt die Art zu Zugriffes (Hin schreiben, Weg lesen). Die Zugriffsfolgen können nun bestimmte Probleme vermuten lassen.
Beispiel Schreiben und sofort nochmal Schreiben -> könnte ein Überschreiben bedeuten oder ein mehrfaches Schreiben könnte eine ineffizienz bedeuten.
Ein weiteres Beispiel ist das lesen von nicht initialisierten Variablen (Lesen ohne vorher zu schreiben.

Schleifen sollten vorsichtshalber zweimal durchlaufen werden um sicherzugehen.

\section{Testverfahren}
\img{0.9}{document/graphics/testverfahren.png}{Testverfahren}{tv}

\paragraph{Unit-Test} sind White-Box Tests durch den Entwickler. Informelles Testen um Fehler zu lokalisieren.

\paragraph{Komponenten-Test} können sowohl als White- als auch als Black-Box Tests durchgeführt werden.

\paragraph{Integrationstest} Black Box in Bezug auf die zu integrierenden Komponenten, White Box in Bezug auf die Integrationsschicht, durch Entwickler.

\paragraph{Systemtest} Black Box durch professionelle Tester.

\paragraph{Regressionstest} Black Box durch Entwickler

\paragraph{Abnahmetest} Black Box durch Kunden

\paragraph{Betatest} Black Box durch Endanwender

\subsection{Testwerkzeuge}
Unit-Tests gibt es für viele Sprachen. Jedoch bleibt die Frage: Wie teste ich den Testcode? Der TestCode testet sich mit dem Programmcode gegenseitig.

\subsubsection{Emulatoren und Simulatoren}

\paragraph{Simulator}
Modell (Vereinfachung) eines Systems zum Zeck der Analyse dieses Systems 

\paragraph{Emulator (Computertechnik)}
Nachbildung wesentlicher Verhaltensaspekte eines Systems durch ein anderes. Anmerkung: Das emulierte wie das emulierende System können aus Hardware und/oder Software bestehen

\chapter{Verifikation und Validierung}

\paragraph{Verifikation von Software}
Überprüfung ob Software ihrer Spezifikation entspricht bzw. den Spezifikationen entsprechend umgesetzt wurde.

\paragraph{Validierung von Software}
Überprüfung ob die Software den Anforderungen und Erwwartungen ihrer Benutzer entspricht - sind die Benutzeranforderungen also richtig und  vollständig erfasst und umgesetzt worden.

Im Normalfall traegt die Verifikation zur Validierung bei, doch sind zusaetzliche Maßnahmen für die Validierung notwendig.

\paragraph{Fehlerquellen}
Ein Anwender beobachtet vermeintliches Fehlverhalten. Missverständnisse und tatsächliche Fehlverhalten müssen voneinander unterschieden werden, was bedeutet, dass der Fehler in der Spezifikation oder Umsetzung liegt.

\section{Planung der Qualitätsprüfung}
Prüfverfahren können statich oder dynamisch stattfinden und die Ziele sind Verifikation Entdeckung von Fehlern in der Software) und Validierung (Aufbau von Vertrauen in die Anwendbarkeit der Software).

\img{0.9}{document/graphics/qualitaetscheck.PNG}{qualitaetscheck}{qualitycheck}

\section{Verifikationstechniken}
Verifikationstechniken umfasst Softwareinstpektion, automatisierte statische Analyse, formale Methoden und Softwaretests.

\subsection{Softwareinstpektion}
Fehlerlokalisierung auf Basis von Test ist eine Art von Inspektion und weitere Prüfziele wie z.B. Normen und Standards, Portiertbarkeit, Wartbarkeit, Eignung von Algorithmen und Programmierstiel könne verfolgt werden.

\paragraph{Voraussetzungen}
Voraussetzungen für die Inspektion sind eine genaue Spezifikation, Vertrautheit der Teammitglieder mit einzuhaltenden Standards und Normen sowie die Verfügbarkeit einer aktuellen zumindestens kompilierbaren Codeversionen.

Bei der Softwareinspektion gibt es mehrere Rollen für die Teilnehmer. Diese Umfassen Autor/Eigentümer, Inspektor, Vorleser, Protokollant, Vorsitzender/Moderator und Chefmoderator.

\img{0.9}{document/graphics/softwareinspektion.PNG}{softwareinspektion}{softwareinspektion}

\subsection{Verifikationstechniken}
\paragraph{Automatisierte statische Analyse}
Softwareinspektion ist eine Form der statischen Analyse und wird oft mit Hilfe von Checklisten und Heuristiken verwendet. 

Statische Analysewerkzeuge erkennen Anomalien im Code (nicht jede Anomalie ist ein Fehler) und diese sollten Gegenstand eines Reviews sein. Solche Anomalien können sein:

\begin{itemize}
\item nicht initialisierte Variablen
\item nicht verwendete Variablen
\item verletzte Indexgrenzen
\item nicht deklarierte Variablen
\item unerreichbarer Code
\item falsch zugeordnete Parametertypen und/oder -anzahl
\item nicht verwendete Funktionsergebnisse 
\item ...
\end{itemize}

Die Phasen der statischen Analyse umspannen die Analyse der Steuerung, unerreichbaren Code un die Pfadanalyse. Außerdem gibt es eine Analyse der Datenverwendeung (Lesen von nicht initialiserten Variabeln, redundante Tests), der Schnitstellen (z.B. Parameteranzahl in Deklaration und Aufruf) und des Informationsflusses (z.B. unbenutzte Eingaben).

\paragraph{Formale Methoden}
Die Vision ist, dass mit Hilfe formaler Methoden die ultimative statische Verfikation möglich ist. Voraussetzungen dafür sind eine vollständige formale Spezifikation. Dies würde die Möglichkeit bieten automatisierte Überprüfungen der Spezifikationen auf Inkonsistenzen zu machen und die Verifikation des Codes gegen Spezifikation ermöglichen.

Ein großes Problem dabei ist, dass die Spezifikation nicht die Benutzeranforderungen sind. Ein Weiteres ist die Komplexität und der Umfang der Beweise und unzutreffende Nutzungsmuster als Voraussetzung des Beweises (was den Beweis ungültig macht). 

\subsection{Validierungstechniken}
Qualitaetssicherung der Anforderungen durch Anforderungsinterviews mit einer Vielzahl unterschiedlicher Beteiltigter bzw. Betroffener sowie Reviews der Anforderungen durch andere Personen die nicht die Anfoderungen erhoben haben (Experten des Anwedungsgebiets, Experten für Systemeigenschaften, ...).

\paragraph{Entwicklungsphase}
In der Entwicklungsphase sollten Design-Reviews für Interkations-Szenarios mit Beteiliten / Betroffenen gemacht werden (Powerpoint.
\paragraph{Validierungsphase}
In der Validierungsphase sollten Tests durch echte Anwender von möglichst allen Anwendergruppen gemacht werden und eine einfache Feedbackmöglichkeit bereitgestellt werden. 
\paragraph{Einsatzphase}
Marktbeobachtungen, Benutzergruppen, Produktwiki

\paragraph{Validierung der Zuverlässigkeit}
Gibt Auskunft darüber wie groß ist der Anteil der korrekten Ergebnisse ist.
Dabei gibt es verschiedene Probleme bei der statistischen Zuverlässigkeitsmessung:

\begin{itemize}
\item Unsicherheit über Betriebsprofil
\item Kosten der Testdatenerstellung
\item Statistische Unsicherheiten
\end{itemize}

\paragraph{Validierung der Betriebssicherheit}
Ist die Eigenschaft eines Systems, bei richtiger wie falscher Benutzerung und auch beim Auftreten externer Fehler kein Verhalten zu zeigen, das Benutzer oder Dritte schädigt oder gefährdet.
Zuverlässigkeit sich zwar messen (ROCOF) aber nicht Betriebssicherheit. 

Die formale Verifikation des gesamten Systems erforder eine vollständige Liste aller, auch externer Fehler --> ist also unmöglich und wäre auch sehr teuer und fehleranfällig. Die Vorgehensweise ist eine formale Definition einer Reihe von Bedrohungen in Form vom Prädikaten. 

\paragraph{Bedeutung von Betriebssicherheit}
Unfälle sind zu selten um sie mit statistischen Verfahren in den Griff zu bekommen und sind sehr oft Verletzungen von "darf-nicht" Anforderungen.

\begin{itemize}
\item Einrichtung eines Systems zur Überwachung von Protokollierung von Unfällen (von der Gefahrenanalyse über die Testphase bis zur Systemvalidierung)
\item Zuweisung von persönlicher Verantwortung für Betriebssicherheit an geeignete Personen
\item Betriebssicherheit-Reviews während des gesamten Prozesses
\item Formale Zertifizierung kritischer Komponenten
\end{itemize}

\paragraph{Validierung der Systemsicherheit}
Das Internet ist eine tolle Infrastruktur um von einem beliebigen Rechner auf ein beliebiges System auf irgendeinem Rechner irgendwo auf der Erde zuzugreifen / angreifen.

Es ist im allgemeinen vollkommen unmöglich nachzuweisen, dass ein System unter keinen Umständen etwas tut, was es nicht tun darf.

Überprüfungsansätze

\begin{itemize}
\item Werkzeuge für erfahrungsbasierte Validierung
\item Checklisten
\item angeheuerte, erfahrene Hacker
\item Formale Verifikation
\end{itemize}

Keine Kette ist stärker als ihr schwächstes Glied!






