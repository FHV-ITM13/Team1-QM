\chapter{Einführung}
Das Hochhalten von Softwarequalität ist eine sehr anspruchsvolle Aufgabe, welche eine gewisse Planung vorraussetzt. Gerade bei Projekten mit hohen Budgets und materiellen Einsätzen werden hohe Anforderungen an das Qualitätsmanagement gesetzt.

Einige bekannte Fehlschläge in der Softwareentwicklung hätten wahrscheinlich mit besseren Qualitätssicherungsmaßnahmen verhindert werden können:

\begin{itemize}
    \item Pioneer 4 verfehlte den Mond
    \item unnötige Mahnungen durch die französische Finanzverwaltung
    \item das Herausgeben von faulen Krediten, was schlussendlich zum Bankencrash geführt hat
    \item Verlust einer Segelyacht im Pazifik
\end{itemize}

\section{Verifikation und Validierung}
Die Begriffe sollten klar getrennt werden, da sie nicht synonym verwendet werden können, und bei Softwareprozessen und Softwarequalität eine gewichtige Rolle spielen.

Die Verifikation stellt fest ob die Software mit der vorhandenen Spezifikation übereinstimmt, wohingegen die Validierung bestimmt ob die Software für den Kunden auch wirklich nützlich ist.

\section{Technical Debt}
Technical Debts sind ein wichtiges Thema in der Qualitätssicherung. Der Begriff wurde aus dem Finanzwesen übernommen (Debt = Schulden). In der Softwareentwicklungen ist damit gemeint, dass ungeschickte Lösungen irgendwann gefixt werden müssen.

Diese technische Schulden kann man bewusst eingehen, um Termine zu halten. Allerdings muss man immer im Hinterkopf behalten, dass man diese Schulden zu einem späteren Zeitpunkt auch wieder bezahlen muss.

Einer der größten Unterschiede zwischen klassischen und agilen Projektmanagementmethoden ist der Umgang mit diesen technischen Schulden. Bei agilen Methoden werden diese Schulden bewusst eingegangen, um ein schnelleres iteratives Vorgehen zu gewährleisten. Bei diesen Methodiken ist allerdings auch die Gefahr einer Überschuldung ungleich höher als bei den klassichen.

Allerdings werden in der Regel auch bei klassischen Methoden technische Schulden verursacht, nämlich in Form von Änderungen in den Anforderungen, auf welche in agilen Methoden besser reagiert werden kann.

\chapter{Hausaufgabe Besprechnung}
Es sollte klar definiert werden was in den Sonderfällen passiert bzw. was in diesen Fällen zurückgegeben wird (z.B. komplexe Zahlen da in Wurzel negative Zahl). Gleitkommzahlen sind "Teufelswerk"! Wenn man zwei gleiche Zahlen (die berechnet wurden aber unterschiedliche Rundungsfehler haben) voneinander voneinander subtrahiert bleibt nicht 0 übrig sondern der Rundungsfehler. Durch Rundungsfehler können somit 2 verschiedene Ergebnisse entstehen die eigentlich eines wären - darum könnte man anstatt der Mitternachtsformel eine andere Formel / einen anderen Ansatz verwenden (z.B. Newton-Näherungsverfahren). 

\begin{quote}"Als Softwareentwickler ist es durchaus erlaubt sein Hirn einzuschalten! - Gleitkommzahlen sind Teufelswerk!"\end{quote} 

\chapter{Wichtige Begriffe}

\begin{itemize}
    \item Softwareprozesse (Abfolge von Tätigkeiten, durch die ein Software-Produkt entsteht)
    \item Vorgehensmodell (Vereinfachte Beschreibung eines Softwareprozesses)
    \item Methode (Strukturierter Ansatz für die Software-Entwicklung)
\end{itemize}

\section{Software-Engineering}
Software-Engineering ist eine technische Disziplin  welche eine Lösung für den Anwender bieten will unter Einsatz von Theorien, Methoden und Werkzeugen und Berücksichtigung von Organisation, Management und Entwicklung. 

\section{Informatik}
Grundlage der Wissenschaft für Software-Ingeneure (Theorie, Konzepte, ...).

\section{ESSENCE Kernel Overview}
\img{0.9}{document/graphics/essence_kernel_overview.png}{ESSENCE Kernel Overview}{EKO}
In diesem Model gibt es verschiedene Zustände für die Anforderungen und jeder dieser Zustände hat selbst wieder Kriterien welche einem dabei helfen in welchem Zustein ein Projekt ist.
\paragraph{Zustände:}
\begin{itemize}
    \item Conceived
    \item Bounded
    \item Coherent
    \item Accepted
    \item Adressed
    \item Fulfilled
\end{itemize}

\section{Qualität}
Grad in dem die inhärenten Eigenschaften des Produkts Anforderungen erfüllen.

\begin{itemize}
	\item \textbf{Explizite Anforderungen}
	\item \textbf{Implizite Anforderungen} - Anforderungen welche existieren aber den Stakeholdern nicht bewusst sind.
	\item \textbf{Nicht explizite Anforderungen} - Stakeholer wissen, dass sie diese Anforderungen gibt aber sie teilen diese nicht mit (sind quasis eh klar).
	\item \textbf{Objektiv} - Vollkommen klar, dass man etwas braucht.
	\item \textbf{Subjektiv} - Vermeintliche Anforderungen, welche nicht wirklich wichtig sind.
	\item alle betroffenen / interessierten Personen
\end{itemize}

\subsection{Begriffsabgrenzung}
\paragraph{Technisches computer-basiertes System} System welches ausschließlich  aus Soft- und Hardware-Komponenten besteht.
\paragraph{Soziotechnisches System} System bestehend aus einem oder mehreren technischen Systemen, den Menschen die es bedienen, den notwendingen Arbeitsprozessen, organisatorischen Richtlinien, usw.

\emph{Systeme:}
\begin{itemize}
	\item haben systemspezifische Eigenschaften die nur dem System als Ganzem zugeordnet werden können
	\item sind häufig nicht deterministisch
	\item hängen von organisatorischen Zielen ab
\end{itemize}

\section{Kritische Systeme}
Relevante Systemeigenschaften für kritische Systeme sind:
\begin{itemize}
	\item Reparierfähigkeit
	\item Wartbarkeit
	\item Überlebensfähigkeit
	\item Fehlertoleranz
\end{itemize}

\paragraph{Kritisches System}
Systeme, bei dessen Ausfall oder Fehlfunktion großen Schaden anrichten kann (wirtschaftliche Verluste, physische Schäden, Gefahr für Gesundheit und Leben von Menschen).

\paragraph{Sicherheitskritisches System}
Schäden an der Umwelt und/oder Gefahr für Gesundheit und Leben von Menschen (Bohrinsel im Golf von Mexiko).

\paragraph{Aufgabenkritisches System}
Aufgaben die ein System erledigen solle werden nicht durchgeführt (z.B. Bank).

\paragraph{Geschäftskritisches System}
Extrem hohe Kosten bzw. signifikante Gewinnausfälle können die Folge eines Systemausfalls sein.


\todo{do fehlt a stuck}

\section{Sammlung von Anforderungen}

\subsection{Interviews}
\paragraph{Technik}
\begin{itemize}
\item Interviews mit Fragebogen
\item Geschlossene Interviews vorgegebener Fragebogen abarbeiten
\item Offene Interviews mit einer Diskussion zwischen Analyseteam und Beteiligten
\end{itemize}

\paragraph{Durchführungsempfehlung}
\begin{itemize}
\item Mischung aller Methoden 
\item Vorbereitung aller Diskussionen als geschlossenes Interview 
\item gut und interessiert zuhören
\item gezielt Fragen
\end{itemize}

\paragraph{Probleme}
\begin{itemize}
\item Jargon des Anwendungsgebiets 
\item Implizites Wissen
\end{itemize}

\paragraph{Eignung}
\begin{itemize}
\item Verständnis der Benutzeranforderungen 
\item Ergänzung zu anderen Informationsquellen mit zum Beispiel Dokumentationen oder Beobachtungen
\end{itemize}

\paragraph{Szenarien}
\begin{itemize}
\item {
Grundbestandteile
\begin{itemize}
\item Ausgangssituation
\item Ereignisablauf
\item Ausnahmen und ihre Behandlung
\end{itemize}
}
\item {
Varianten
\begin{itemize}
\item Ad-hoc
\item Formell
\end{itemize}
}
\end{itemize}

\subsection{Ethnografische Methode (Völkerkunde)}
Grundidee: Beobachten ohne einzugreifen

\begin{itemize}
\item Beobachten der alltäglichen Arbeit im normalen Umfeld
\item Notieren von Auffälligen
\item Diskussion mit Experten
\item Ableitung der Anforderungen
\end{itemize}

\paragraph{Stärken}
\begin{itemize}
\item Erkennen von impliziten Anforderungen 
\item Erkennen von nicht explizierten Anforderungen
\item Erkennen von Abweichungen
\end{itemize}

\img{0.9}{document/graphics/ethnogfrafisch.png}{Verknüpfung von Ethografie und Prototypen nach Sommerville (Copyright Pearson Studium 2007)}{ethnogfrafisch}

\newpage
\section{Klassifizierung von Anforderungen}

\img{0.8}{document/graphics/metamodel.png}{Metamodell}{metamodel}

\paragraph{Aufgaben}

\begin{itemize}
\item Erkennen von Duplikaten / Synonymen 
\item Beziehungen zwischen Anforderungen 
\item Gruppierung der Anforderungen 
\end{itemize}

\section{Validierung von Anforderungen}
Wichtige Prüfungen sind:

\begin{itemize}
\item Gültigkeitsprüfung
\item Konsistenzprüfung
\item Vollständigkeitsprüfung (schwierig, aber mit etwas Bauchgefühl machbar)
\item Realisierbarkeitsprüfung
\item Verifizierbarkeitsprüfung
\end{itemize}

\subsection{Techniken}
Prototypen erstellen und Testfälle entwickeln. Falls das nicht möglich sind die Anforderugnen schlecht definiert.

\subsection{Review}
\paragraph{Teamzusammensetzung}
Es sollten Vertreter aller am Projekt beteiligten bzw. vom Projekt betroffenen Gruppen auf Anwenderseite, ausserdem Systemarchitekten und Vertreter der Softwareentwickler.

\paragraph{Durchführung}
Die Führung der Analyse liegt bei den jeweiligen Anwendervertretern. Diskutiert werden sollten alle Anforderungen. Dadurch können Fehler, Konflikte und Wiedersprüche aufgedekt werden. Das Ergebnis ist ein Review Bericht.

\paragraph{Prüfungen}
Die Konsistenz der Anforderungen sollten am Ende geprüft werden. Ausserdem sollte eine Vollständigkeitsprüfung durchgeführt werden.

\subsection{Priorisierung von Anforderungen}

\paragraph{Grundgedanke}
Phasenweise Implementierung der Software. 

\subsubsection{Prioritätsfestlegung}
Teams festlegen, die nicht miteinander kommunizieren sollten. Ausserdem wird eine Bewertungsformel festgelegt.

\paragraph{Nutzwertanalyseteam}
Bewertet den Nutzen für die Anwender.

\paragraph{Kostenanalyseteam}
Schätzt die Kosten jeder Anforderung


\subsubsection{Auswertung}

\paragraph{Einflussgrößen}
\begin{itemize}
\item Nutzwert jeder Anforderung
\item Kosten jeder Anforderung
\item Obergrenze des Aufwands für Stufe 1
\item Abhängigkeiten
\end{itemize}

\paragraph{Ergebnis}
Liste der Anforderungen für nächste (bzw. erste) Ausbaustufe

\newpage
\section{Systemmodelle}

\paragraph{Kontextmodelle}
Definiert die Systemgrenzen des Gesamtsystems und des technischen Systems. Das Gesamtsystem umfasst das Technische System und die Menschliche Komponente und definiert den Kontext. Das Technische System definiert den Scope.

\img{1}{document/graphics/kontextmodelle.png}{Kontextmodelle}{kontextmodelle}

\newpage
\paragraph{Verhaltensmodelle}
Definiert die Abläufe in einem System. Sie können Datenfluss (Datenfocus) - oder Ereignis (Ereignisfocus) - Orientiert geschehen. Aussderm gibt es Mischformen davon. Dafür können Datenflussdiagramme (Abbildung \imgref{verhaltensmodelle}), Zustandstabelld (Abbildung \imgref{zustandstabelle}) und ähnliches verwendet werden.
 
\img{1}{document/graphics/verhaltensmodelle.png}{Datenflussdiagramm}{verhaltensmodelle}

\img{1}{document/graphics/zustandstabelle.png}{Zustandtabelle}{zustandstabelle}

\paragraph{Datenmodelle}
Definiert die logische und persistente (lokal, übergreifend mttels Datenbank und Datenaustausch) Datenstruktur. Dazu kann ER-, UML-Diagramme, OWL oder andere Ontologie-Darstellungen und andere.
 
\newpage
\paragraph{Objektorientierte Modellierung}
Vereinigt die Funktionalität von Daten- und Verhaltensmodelle und können Daten, Datenflüsse, Datenstrukturen und Erreignise erfassen. Als Notation wird meist UML verwendet.

\img{1}{document/graphics/objektorientiert.png}{Objektorientierte Modellierung}{objektorientiert}

Sind die Klassen in dem Diagramm Abbildung \imgref{objektorientiert} wirklich \textbf{Klassen oder Rollen}? Nein das sind eindeutig Rollen.

\newpage
\paragraph{Strukturierte Methoden}
Detailliert definierte Vorgehensweise bei der SW-Entwicklung. Normalerweise basierend auf einem Satz von Diagrammtypen. Definiert zusätzliche Regeln und Richtlinien. Beispiele dafür sind JSP, V-Modell oder RUP. Nachteile davon sind Mangelnde Unterstützung nicht-funktionaler Anforderungen und Anwendbarkeit für konkretes Problem oft schwer zu entscheiden.

\img{1}{document/graphics/strukturiert.png}{Strukturierte Methoden}{strukturiert}

\section{Anforderungsmanagementsystem}
Die Anforderungen an ein System ändern sich mit der Zeit, diese können ursprünglich unvollständig sein. Oder es verbessert sich das Verständnis des Problems / es ensteht eine bessere Sicht der Dinge. Aber auch das Umfeld kann sich verändern, z.B. wirtschaftlich, technisch, juristisch ...

Der Prozess umfasst:

\begin{itemize}
\item {
das
\begin{itemize}
\item Sammeln 
\item Verstehens 
\item Klassifizierens 
\item Validierens 
\item Priorisierens
\end{itemize}
}
\item {
von
\begin{itemize}
\item Anforderungen 
\item Änderungen der Anforderungen 
\end{itemize}
}
\item {
und ihren Auswirkungen auf 
\begin{itemize}
\item andere Anforderungen 
\item Entwurfsentscheidungen
\item das System
\end{itemize}
}
\end{itemize}

\paragraph{Dauerhafte Anforderungen}
Sie sind relativ stabil und sind mit dem Kern der Anwendung verwoben. Oft aus Standardisierten Modellen entnohmen.

\paragraph{Veränderliche Anforderungen}
Anforderungen mit hoher Änderungswahrscheinlichkeit. Können wirtschaftliche Randbedingungen, technische Randbedingungen und gesetzliche Randbedingungen.

\section{Pflichtenheft}
Zusammenstellung der vollständigen und detailierten Benutzeranforderungen und Systemanforderungen (großes Problem ist die Vollständigkeit). Darf nach Fertigstellung nicht mehr geändert werder und muss so implementiert werden wie es festgehalten wurde (auch wenn es sich um kompletten Blödsinn handelt). Dies muss aus juristischen Gründen so sein da eine nachträgliche Änderung als eine Benachteiligung der Mitbewerber interpretiert werden kann.

\paragraph{Synonyme} sind die Begriffe Produktdefinition, Produktspezifikiation, Systemdefinition und Systemspezifikation.

\paragraph{Adressaten des Pflichtenhefts} sind unter anderem Systemkunde, Manager, Systementwickler, Systemtester, Systemwarter und Juristen. 

\paragraph{Informationen im Pflichtenheft} sind qualitative und quantitative Anforderungen (mandatory requirement)sowie zusätzliche Wünsche (optional requirements) dessen Erfüllung als sehr positiv betrachtet werden und informative Bestandteile. Diese Bestandteile dienen dem Verständniss und sind streng genommen unverbindliche Informationen.

In vielen Ländern gelten Abbildungen, Tabelle und Anhänge als informative Bestandteile, wenn sie nicht anderst gekennzeichnet sind (engl. "normativ").

\paragraph{Aufbau des Pflichtenhefts}
\begin{itemize}

\item { Einleitung
\begin{itemize}
\item Ziele des Pflichtenhefts
\item Anwendungsbereich des Produkts
\item Definitionen, Akronyme und Abkürzungen
\item Referenzen
\item Überlick über das Pflichtenheft
\end{itemize}
}

\item { Allgemeine Beschreibung
\begin{itemize}
\item Produktperspektive
\item Produktfunktion
\item Produktcharakteristika aus Benutzersicht
\item Beschränkungen
\item Voraussetzungen und Abhängigkeiten
\end{itemize}
}

\item Spezifische Anforderungen (funktionale u. nicht funktionale Anforderungen)

\item Anhänge
\item Index

\end{itemize}

\section{Anforderungen an kritische Systeme}

\paragraph{Funktionale Anforderungen} unterstützen Definition von Funktionen zur Fehlerprüfung, zur Wiederherstellung im Fehlerfall und Aspekte zum Schutz gegen Systemausfälle.

\paragraph{Als nichtfunktionale Anforderungen} werden u.a. die Systemzuverlässigkeit und Systemverfügbarkeit festgelegt. 

\paragraph{Negativanforderungen} Beschreibung von Verhalten oder Eigenschaften, die das System auf keinen Fall zeigen darf.

\section{Risikomanagement}
Risikomanagement besteht aus Gefahrenbestimmung, Risikoanalyse und Gefahrenklassifizierung, Gefahrenvereinzelung und Festlegung zur Risikominimierung.

\paragraph{Murphys Law} Alles was schief gehen kann, wird irgendwann einmal schief gehen.

\paragraph{Risikoerkennung} Ziel ist es zu Erkennen von Rsikiken und Gefahren. Probleme die dabei entstehenkönnen sind die Wechselwirkung zwischen Systemkomponenten bzw. die Wechselwirkungen mit der Umwelt. 

\paragraph{Risikoanalyse und Risikoklassifizierung} Analyse von  Unfallwahrscheinlichkeit, Schadenswahrscheinlichkeit und Schadeshöhe. Risiken sind klassifizierbar in:

\begin{itemize}
\item { nicht tolerierbar
\begin{itemize}
\item großer Schaden und / oder hohe Schadenswahrscheinlichkeit
\item Maßnahmen: unter allen Umständen Risiko ausschließen
\end{itemize}
 }
\item {as low as reasonably possible (ALARP)
\begin{itemize}
\item höchstens mittleres Schadenspotential und mittlere Schadenswahrscheinlichkeit
\item Maßnahmen: zumindestens Auschluss des Schadens unter Beachtung von wirtschaftlichen, vertraglichen oder technischen Randbedingungen
\end{itemize}
 }

\item { vernachlässigbar
\begin{itemize}
\item geringes Schadenspotential und / oder geringe Schadenswahrscheinlichkeit
\item Maßnahmen: Reduzierung der Schadenswahrscheinlichkeit ohne negativen Einfluss auf wirtschaftliche, technisches, oder vertragliche Randbedingungen oder andere Systemanforderungen
\end{itemize}
}

\end{itemize}


\paragraph{Risikozerlegung} Ziel es die Ursachen aufzudecken. Dazu können Reviews, Checklisten, Petri-Netze, formale Login und Fehlerbäume verwendet werden.

\img{0.9}{document/graphics/fehlerbaum.png}{Fehlerbaum}{FB}

\paragraph{Risiko-Minimierung} Ziel ist das Vermeiden des Auftretens von Gefahren. In der Praxis bedeutet dies eine Kombination aller Strategien.

\section{Betriebssicherheit}

\img{0.9}{document/graphics/betriebssicherheit.png}{Betriebssicherheit nach IEC 61508}{BS}

\paragraph{Klassifizierung}

\begin{itemize}
\item Klasse 1 - Fehler die andere Anwedungen betreffen können
\item Klasse 2 - Fehler die andere Benutzer der selben Anwedung betreffen können
\item Klasse 3 - Wesentliche Funktion steht ohne Work-Around nicht zur Verfügung
\item Klasse 4 - Wesentliche Funktion steht nur über Work-Around zur Verfügung bzw. Sekundärfunktion steht nicht zur Verfügung
\item Klasse 5 - Verbesserungswunsch
\end{itemize}

\section{Systemsicherheit} Hierbei geht es um direkte und indirekte Berodhungen.

\paragraph{Direkte Bedrohung} wie z.B. unbefugtes Eindringen und DOS.

\paragraph{Indirekte Bedrohung} wie Aufwand um Sicherheitsmaßnahmen zu installieren, konfigurieren und aktuell zu halten. Auch inkludiert sind Fehler und Nachlässigkeiten der Systemverwalter und monopolartige Stellungen einiger Hard- und Softwareanbieter da eine weite Verbreitung von Sicherheitslücken sehr wahrscheinlich ist.

\img{0.9}{document/graphics/sicherheit.png}{Sicherheit}{Sec}

\section{Zuverlässigkeit} besteht aus Hardware-, Software- und Bedienerzuverlässigkeit. 

\img{0.9}{document/graphics/zuverlaessigkeit.png}{Zuverlässigkeit}{Zuv}

\img{0.9}{document/graphics/zuverlaessigkeit2.png}{Zuverlässigkeit nach Sommervill}{Zuv}

\paragraph{Extreme Zuverlässigkeitsanforderungen} lassen sich nicht testen!

\section{Formale Spezifikationsmethoden}
An dieses Thema sind seit 1970 sehr hohe Erwarungen gerichtet aber der große Durchbruch blieb bisher aus. Gründe dafür sind die Entwicklung anderer Software-Engineering-Methoden, Marktveränderungen, beschränkte Einsetzbarkeit und mangelhafte Skalierbarkeit. 

Erfolgreich verwendet wirds bei Raumfahrt-, und medizinischen Systemen sowie bei Überwachung des Luftverkehrs. 

\img{0.9}{document/graphics/formale-spezifikationsmethoden.png}{Formale Spezifikationsmethoden im Softwareprozess}{FSIS}

\paragraph{Fazit}
Formale Spezifikationstechniken sind gute Ergänzungen, eindeutig und präzise aber schwer verständlich für den Laien. Erzwingen die frühzeitige Analyse der Systemanforderungen wenn die Fehlerbehebung noch billig ist.

\section{Beispiel: Anforderungen an Quadratische Gleichungen lösen}

\begin{itemize}
\item Ergebnis x element aus Reelen Zahlen : $ax^2+bx+c=0$
\item Kein Absturz bei komplexer Lösung
\item {
Vernünftige Reaktion auf Eingabefehler
\begin{itemize}
\item unvollständig
\item $4ac > b^2$
\end{itemize}
}
\item Maximaler Rundungsfehler: Relativ 0,1\% + Beweis
\item Immer Definiertes Ergebnis (Ausnahmebehandlung)
\item Keine Endlosschleife
\item {
Zeitbedarf max 1mSec
\begin{itemize}
\item Verwendeter CPU / Prozessor / Rechner
\item Maximal 2xSQRT einer bestimmten implmentierung
\end{itemize}
}
\item {
Signatur
\begin{itemize}
\item Nmae
\item parameter
\item Ergebnis (Return)
\end{itemize}
}
\end{itemize}


\chapter{Entwurf}

\todo{???}

\chapter{Entwicklung}

\paragraph{Strategien}
\begin{itemize}
\item Fehlervermeidung
\item Fehlerentdeckung
\item Fehlertoleranz
\end{itemize}

Laut der Kostenentwicklung nach Sommerville ist eine Software mit vielen Fehlern günstiger als eine Software mit weniger Fehlern. Jedoch steigen die Kosten nicht linear sondern exponentiell.

\paragraph{Techniken}
\begin{itemize}
\item Verlässliche Softwareprozesse
\item Qualitätsmanagement
\item Formale Spezifikation
\item Statische Verifikation (Probleme durch Reviews beheben)
\item Starke Typisierung
\item Sichere Programmierung
\item Ausnahmebehandlung
\item Geschützte Information
\end{itemize}

\subsection{Fehlervermeidung}
\paragraph{Verläsliche Softwareprozesse}

\begin{itemize}
\item Inspektion der Anforderungen
\item Anforderungsmanagement
\item Überprüfung der Modelle: statisch / dynamisch
\item Inspektion des Entwurfs / Codes
\item Statische Analyse des Codes (Review)
\item Planung und Management von Tests
\item Konfigurationsmanagement
\end{itemize}

\paragraph{Sichere Programmierung}
\begin{itemize}
\item sichere verwendung von GOTO (mach da weiter ohne überprüfung)
\item sichere verwendung von POINTER (such da mal nach deinen daten => goto in der Datenwelt)
\item Rundungsfehler von Gleitkommazahlen
\item Dynamische Speicherallokierung
\item Parallelität
\item Rekursion
\item Interrupts
\item Vererbung
\item Aliasing
\item Fehlende Überprüfung von Arraygrenzen
\item Konfiguationsdateien
\end{itemize}

\paragraph{Ausnahmebehandlung}
Wird in manchen Sprachen mangelhaft Unterstützt (Beispiel: C). Kann auch dazu verwendet werden um die Lesbarkeit der Anwendung zu erhöhen und damit können Fehler vermieden werden.

\subsection{Fehlertoleranz}

\paragraph{Fehlererkennung}
Typen sind Vorbeugend (ich versuche vorher Fehler zu erkennen) und Rückblickend (ich behebe den Fehler wen einer auftritt => z.B. die Transaktion zurücksetzen).

\paragraph{Wichtige Hilfsmittel}
Validierung: Invarianten, Vorbedinungen, Nachbedinungen => dürfen nicht abschaltbar sein.

\paragraph{Wiederherstellung nach Fehlern}
Pesimistisch (nur zurücksetzen geht nicht ...) oder Optimistisch (erneut versuchen den gewünschten zustan zu erreichen).

Vorbeugende Fehlererkennung hilft diesen Aufwand zu vermeiden.

\subsubsection{Fehlertolerante Architekturen}
\paragraph{Widerherstellungsblöcke}
Verschiedene Algorithmen implementieren. Im Betrieb den ersten ausführen und testen, bei Fehler nimm nächsten Algorithmen. Probleme: Rundungsfehler

\subsection{Wartungsaufwand}
Gründe für hohen Wartungsaufwand sind Informatinosmanagement (Verlust des Entwicklungsteam und seiner Erfahrung), Vertragliche Zuständigkeit (Entwicklung von einer Firma, wartung von einer anderen), Fähigkeiten der Metarbeiter (Mangelnde Erfahrung mit dem Anwendungsgebiet und Technologien) und Alter bzw. Struktur des Programs (Dokumentation nicht mehr aktuell oder nicht verhanden, fehlendesKonfigurationsmanagement).

Zusätzlichen Entwicklungsaufwand um Software besser wartbar zu machen zahlt sich im allgemeinen nicht aus. 

\subsection{Weiterentwicklungsprozesse}
Es gibt für jede Anforderung einen passenden Prozess (laufende weiterentwicklung, änderungungen, Bug-Behebungen, ...)

\subsubsection{Software-Reengineering}
Dabei handelt es sich um eine Neuentwicklung von Software, meistens eine Umstellung auf neuere Technologien (z.B. von COBOL auf Java).

Dafür ist auch das Beherrschen der alten Technologien notwendig, da man andernfalls das alte System nicht analysieren kann. Die Beweggründe hinter der Umstellung ist ein verringertes Risiko und geringere Kosten.

Normalerweiße teilt sich das Reengineering in Reverse Engineering und in eine Verbesserung der Programmstruktur. Im Anschluss daran müssen natürlich auch die Daten auf eventuell neue Formate transformiert werden.

\subsubsection{Legacy Systeme}
Legacy Systeme werden nach zwei Kriterien beurteilt: Qualität und Geschäftswert.

Wenn beide Kriterien schlecht sind wird die Software nicht mehr weiterentwickelt. Bei hoher Qualität kann man das einfach weiter laufen lassen, bei hohem Geschäftswert aber niedriger Qualität wird das komplett neu geschrieben, und wenn beide Kriterien hoch einzustufen sind rentiert sich ein Software Reengineering Ansatz.

\chapter{Testing}
Betrifft die Kernel Alphas Softwaresystem, Requirements und Work. Tests sollen uns helfen Probleme zu entdecken und beheben, die Kunden überzeugen und die Softwarequalität demonstrieren. Dabei ist allerdings zu beachten, dass nur die Anwesenheit von Fehlern getestet werden kann, allerdings nicht ihre Abwesenheit.

\begin{itemize}
    \item Fehlverhalten (Failures) beschreiben ein inkorrektes Verhalten eines Systems zur Laufzeit
    \item Fehler kommen wirklich im Quellcode vor
    \item Irrtürmer (Errors) sind inkorrekte Wahrnehmungen von Menschen
\end{itemize}

Dabei muss es nicht zwingendermaßen sein dass nicht jeder Irrtum zu einem Fehler, und nicht jeder Fehler zu einem Fehlverhalten führt.

Für die Reduzierung von Fehlern gibt es verschiedene Maßnahmen, z.B. das 4-Augen-Prinzip zur Vermeidung, Tests zum Entdecken, und standardisierte Prozesse zum Beseitigung von Fehlern.

Weiters wird zwischen Blackbox- und Whitebox-Tests unterschieden, bei Blackbox Tests wird rein gegen die Spezifikation getestet, ohne den Code zu testen, wohingegen Whitebox-Tests den Code berücksichtigen.

Ein weiterer Typ ist ein Regressionstest, der neben der erwarteten Funktionalität sicherstellen soll, dass das System frei von alten Fehlern ist. Das Einführen alter Fehler kann sehr schnell passieren, wenn Code mit anderen Absichten refactored wird.

Ein Testfall wird in einen abstrakten und konkreten Teil eingeteilt. Der abstrakte Teil beschreibt den Test, der konkrete ist eine Ausführung des Tests. Eine Testsuite vereint mehrere Tests zu einer Ausführungseinheit.

\section{Testprozesse}
Ein Testprozess muss geplant und vorbereitet werden. Dazu gehören die Definitionen der Testziele und verwendeten Messungen, sowie die Eingabewerte und Testsuites.

Die Messungen müssen dann auch noch analysiert werden, vor allem geht es da um das Auffinden von Fehlern. Diese Fehler müssen von Softwareentwicklern behoben werden, insofern bei der Planung der Messungen keine Fehler gemacht werden. Bei TDD testen sich die Software und Tests gegenseitig, da beim Auftreten eines Fehlers sowohl das System under Test als auch der Test selbst fehlerhaft sein kann.

\subsection{Teststrategien}
\subsubsection{Ausprobieren}
Planloses Ausprobieren ist die häufigste Form des Testens, allerdings ist diese Form des Testens in vielen Fällen unzureichen. Es liefert keine reproduzierbare Ergebnisse, und erlaubt auch keine Aussage über die Qualität.

Das ist vor allem unzureichend wenn man eine Gewährleistung auf die Software geben will. Die rechtlichen Rahmenbedingungen sind momentan noch im Sinne der Softwareanbieter, allerdings könnte sich das in Zukunft ändern, gerade selbstfahrende Autos könnten da Ausschläge in diese Richtung geben.

\subsubsection{Vollständiges Testen}
Das vollständige Testen ist meist theorethisch möglich, aber nur in den seltensten Fällen wirtschaftlich. Unser Ziel muss es deshalb sein eine möglichst hohe Testabdeckung zu erreichen, und dabei auch noch wirtschaftlich zu bleiben.

\subsubsection{Checklisten}
Ein mögliches Vorgehen sind Checklisten, die die wesentlichsten Funktionen des Systems definieren, und nur diese getestet werden. Natürlich kann man Checklisten auch für andere Kritieren definieren.

Wenn man sichere Aussagen über die Qualität machen will, wird man sehr umfangreiche Checklisten bekommen. Andererseits ist der Vorteil das man eine verbesserte Reproduzierbarkeit erhält, allerdings wird sich niemand die Zeit nehmen vollständige Checklisten zu erstellen.

\subsubsection{Partitionen}
Eine Partition ist eine nicht überlappende Menge von Untermengen einer Menge, die bei der Beseitigung der Nachteile von Checklisten behilflich sein können. Diese Untermengen werden als Äquivalenzklasse bezeichnet, und es reicht wenn nur ein Element einer Äquivalenzklasse getestet wird. Bei sinnvoller Partitionierung kann der Testaufwand bei gleichzeitig erhöhter Qualität verringert werden.

Durch die gleiche Gewichtung der Äquivalenzklassen führt allerdings zu unwirtschaftlicher Verteilung der Testaufwände. Administrationwerkzeuge werden z.B. weit weniger aufgeruft, und haben dadurch schon eine niedriger Fehlereintrittwahrscheinlichkeit. 

\subsubsection{Benutzungsprofile}
Da das Testen mit Partitionen immer noch sehr aufwändig sein kann, ist die Verwendung von Benutzungsprofilen möglich. Dabei wird die Benutzung der Partitionen mit einberechnet, und man kann damit mehr Testaufwand für mehr benutzte Partitionen aufwenden.

Bei existierenden Produkten kann für die Erstellung der Benutzungsprofile anhand des aktuellen Produkts bzw. von Vorgängerversionen gemacht werden. Bei neuen Produkten muss man hier wohl auf ein Konkurrenzprodukt zurück greifen. Bei einem komplett neuartigen Produkt bleibt einem nur noch das Schätzen übrig, wobei man hier auf Fachleute der jeweiligen Domäne heranziehen sollte.

Hilfreich ist hier die Definition von Kundenprofilen, die danach anhand der Benutzung gewichtet werden.

\subsubsection{Überdeckung}
Die Partitionen werden auf Basis der Eingabedaten gemacht. Die Eingaben in einer Partitionen müssen gleich behandelt werden. Z.B. realle/imaginäre Lösung der Eingabe für unser Lösungsprogram.

Die größte Fehlerwahrscheinlichkeit besteht an der Partitionsgrenzen. Wenn ein Array z.B. 100 Elemente umfasst, so sollte auch das Einfügen am Index 100 getestet werden, da hier bereits kein Fehler auftreten sollte.

Partitionen sollten Überlappungsfrei und vollständig sein, um eine möglichst hohe Testqualität zu gewährleisten. Für jede Unterdomäne müssen Eingaben ausgewählt werden, für die dann Tests durchgeführt werden. Im Idealfall werden so alle Möglichkeiten im Code abgearbeitet.

Probleme die auftreten können sind unter anderem widersprüchliche Verarbeitungsregeln (überlappende Unterdomänen) oder Probleme mit Rundungsfehlerdurch Grenzdefinitionen. Auch überflüssige Grenzen werden in einen unnötig hohen Testaufwand resultieren.



